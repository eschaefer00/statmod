{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood I\n",
    "\n",
    "## Binomial distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Bernoulli distribution\n",
    "\n",
    "A random variable $A$ which can take one of two discrete states with a probability $\\theta$ of taking the first state (like you have seen above) is called a Bernoulli RV.  Its probability mass function is\n",
    "\n",
    "\\begin{align}\n",
    "    P(A = 1) = \\theta\n",
    "\\end{align}\n",
    "\n",
    "Pretty straightforward, right? The standard example is a coin toss, where $\\theta = \\frac{1}{2}$ for a fair coin. For this reason, it is often called a \"success\" in the statistical literature when the RV is equal to one.\n",
    "\n",
    "Let's look at the probability mass function. Notice how it is pretty much the same as our area plot in the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e62bf1cd8254e5fb5bd58b330bb3025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='$\\\\theta$', max=1.0), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(theta=widgets.FloatSlider(min=0., max=1., value=0.5, description=r\"$\\theta$\"))\n",
    "def plot_bernoulli_pmf(theta):\n",
    "    bar = plt.bar([0, 1], [1-theta, theta])\n",
    "    bar[1].set_color(\"C1\")\n",
    "\n",
    "    plt.ylim(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The binomial distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It becomes a little more interesting when we sample $n$ Bernoulli RVs and ask the question how many of them are equal to 1. This number of successes $k$ for a sequence of $n$ Bernoulli trials is called a binomial RV. The probability mass function is:\n",
    "\n",
    "\\begin{align}\n",
    "    P(X = k | \\theta) = {n \\choose k} \\theta^k (1 - \\theta)^{n - k}.\n",
    "\\end{align}\n",
    "\n",
    "The first term in the equation ${n \\choose k}$ is the number of possible ways for choosing $k$ out of $n$ elements. It is known as the binomial coefficient, hence the name of the distribution. The next term is the probability that $k$ successes followed by the probability of $n - k$ failures. Take a look at the binomial distribution for different values of $n$, and $\\theta$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965b19e6ef7445a497b4c6a1f4312c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='$\\\\theta$', max=1.0), IntSlider(value=10, descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.special import comb\n",
    "\n",
    "def binomial_pmf(theta, n, k):\n",
    "    return comb(n, k) * theta**k * (1 - theta)**(n - k)\n",
    "\n",
    "@interact(theta=widgets.FloatSlider(min=0., max=1., value=0.5, description=r\"$\\theta$\"),\n",
    "         n=widgets.IntSlider(min=1, max=100, step=1, value=10), description=r\"$n$\")\n",
    "def plot_binomial(theta, n):\n",
    "    k = np.arange(0, n + 1)\n",
    "    \n",
    "    p = binomial_pmf(theta, n, k)\n",
    "    \n",
    "    plt.bar(k, p)\n",
    "    plt.xlabel(r\"$k$\")\n",
    "    plt.ylabel(r\"$p(k | \\theta)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how:\n",
    "\n",
    "- the distribution becomes more skewed when $\\theta$ is closer to 0 or 1\n",
    "- the Bernoulli distribution is special case of the binomial for $n = 1$\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The likelihood function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability mass function of the binomial distribution as seen in the visualization above gives you the probability of each value of $k$ given a fixed $\\theta$. It is the conditional distribution of $k$ given $\\theta$. In most realistic scenarios, however, we do not know the true probability $\\theta$, but merely have a measurement of $k$ and $n$. For example, in a decision making task, we have observed that a subject has made $k = 24$ correct decisions in $n = 32$ trials. We now want to know their probability of making a correct decision. It seems straightforward to say \"Of course it is 24 / 32 =  0.75\". But why is that? Can we make our intuition more formal?\n",
    "\n",
    "We can do this by introducing the concept of a likelihood function. The likelihood function is the probability mass function $P(X = k | \\theta)$ as a function of $\\theta$. It is not a probability distribution w.r.t. $\\theta$, since it does not normalize to 1 when integrating over all possible values of $\\theta$.\n",
    "\n",
    "Let us look at the likelihood function. It tells us how likely the data we observed are given different values of $\\theta$. Implement the following steps:\n",
    "\n",
    "1. Choose a true value for $\\theta$\n",
    "2. Sample the number of successes $k$ for a number of trials $n$ from the Binomial distribution, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html\n",
    "3. Plot the likelihood function.\n",
    "4. What would be a good guess $\\hat \\theta$ about $\\theta$ based on this likelihood function? Does this agree with our intuition from above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "theta_true = 0.8 # as an example\n",
    "n = 32 # as an example\n",
    "k = ... # your code here\n",
    "\n",
    "\n",
    "def plot_likelihood(n, k, theta_true):\n",
    "    theta = np.linspace(0, 1, 100)\n",
    "    \n",
    "    # compute and plot the likelihood function\n",
    "    ... # your code here\n",
    "    \n",
    "    plt.axvline(theta_true, label=r\"$\\theta$\", linestyle=\"--\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.xlabel(r\"$\\theta$\")\n",
    "    plt.ylabel(r\"$p(k | \\theta)$\")\n",
    "\n",
    "plot_likelihood(n, k, theta_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, repeat this process 100 times:\n",
    "1. Sample $k$ for a given $n$ and $\\theta$\n",
    "2. Compute the maximum likelihood estimate $\\hat\\theta$\n",
    "\n",
    "Collect your results in a `numpy.array` and try to answer the following questions: Is the maximum likelihood estimate of $\\theta$ \"correct\" on average? How does the number of trials $n$ influence this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood II\n",
    "\n",
    "## Gaussian distribution\n",
    "\n",
    "Now, we are doing basically the same thing for the Gaussian distribution. \n",
    "\n",
    "1. Generate some data $D = \\{x_1, \\dots, x_n\\}$ from a Gaussian distribution with a true mean $\\mu$ of your choice and standard deviation fiexed at $\\sigma = 1$, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html\n",
    "2. Plot a histogram of the data\n",
    "3. Based on these data, what should your estimate $\\hat \\mu$ about the mean be, intuitively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 25\n",
    "mu_true = 10 # for example\n",
    "\n",
    "# your code here\n",
    "x = ...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood function\n",
    "\n",
    "1. Compute the likelihood function $p(D \\, | \\, \\mu)$ for a range of different values for $\\mu$. Use the fact that the individual data points $x_i$ are identically and independently distributed (i.i.d.)\n",
    "2. Plot the likelihood function. Where is its maximum at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
